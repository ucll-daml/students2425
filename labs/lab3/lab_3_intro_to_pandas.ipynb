{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\Logo_UCLL_ENG_RGB.png\" style=\"background-color:white;\" />\n",
    "\n",
    "# Data Analytics & Machine learning\n",
    "\n",
    "Lecturers: Aim√©e Lynn Backiel, Daan Nijs, and Kenric Borgelioen\n",
    "\n",
    "Academic year 2024-2025\n",
    "\n",
    "## Lab 3: Data analytics with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. Recap last week\n",
    "2. Introduction to the case\n",
    "3. Data exploration using Pandas\n",
    "   1. Univariate analysis\n",
    "   2. Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of last lecture(s)\n",
    "\n",
    "#### Lab 1\n",
    "\n",
    "1. We ensured we had a valid Python installation.\n",
    "2. We learnt what a virtual environment is:\n",
    "   * Isolated Python executable and packages.\n",
    "   * We created a virtual environment.\n",
    "3. Absolute path vs relative path recap.\n",
    "4. Recap of data structures in Python\n",
    "\n",
    "#### Lab 2\n",
    "1. Installed Pandas\n",
    "2. Learnt how to read data\n",
    "3. Learnt how to calculate mean, mode, median etc.\n",
    "4. Basic exploration of the 4 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Turing Travelogue, or as everyone calls her, Ada just started working part time at her parents travel agency. She has a keen understanding and interest of everything related to applied computer science ranging from server & system management to full stack software development. Through database foundations she already understands how to query data and programming 1 and 2 covered the essentials about the Python programming language. Recently she has just decided to start learning about data analytics & machine learning as well.\n",
    "\n",
    "She uses her skills to connect to the travel agency's database where she finds many, normalized, tables. Ada recalls what she learnt in database foundations and performs all the correct joins. Afterwards she saves the data in the `data/` folder.\n",
    "\n",
    "\n",
    "She finds the following dataset:\n",
    "\n",
    "| Column Name          | Description                                                                                       |\n",
    "| -------------------- | ------------------------------------------------------------------------------------------------- |\n",
    "| SalesID              | Unique identifier for each sale.                                                                  |\n",
    "| Age                  | Age of the traveler.                                                                              |\n",
    "| Country              | Country of origin of the traveler.                                                                |\n",
    "| Membership_Status    | Membership level of the traveler in the booking system; could be 'standard', 'silver', or 'gold'. |\n",
    "| Previous_Purchases   | Number of previous bookings made by the traveler.                                                 |\n",
    "| Destination          | Travel destination chosen by the traveler.                                                        |\n",
    "| Stay_length          | Duration of stay at the destination.                                                              |\n",
    "| Guests               | Number of guests traveling (including the primary traveler).                                             |\n",
    "| Travel_month         | Month in which the travel is scheduled.                                                           |\n",
    "| Months_before_travel | Number of months prior to travel that the booking was made.                                       |\n",
    "| Earlybird_discount   | Boolean flag indicating whether the traveler received an early bird discount.                     |\n",
    "| Package_Type         | Type of travel package chosen by the traveler.                                                    |\n",
    "| Cost                 | Calculated cost of the travel package.                                                            |\n",
    "| Margin | The cost (for the traveler) - what the travel agency pays. |\n",
    " | Additional_Services_Cost| The amount of additional services (towels, car rentals, room service, ...) that was bought during the trip. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping Ada explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal for the remainder of this lab is to explore the data. We will specifically take four columns:\n",
    "\n",
    "* Cost\n",
    "* age\n",
    "* stay length\n",
    "* Destination\n",
    "\n",
    "Our goal is to find interesting relationships between them.\n",
    "\n",
    "As was covered in the book and lecture there are to main data types in analytics: categorical and continuous data. This is a crucial first step in your analysis because it determines what methods make sense on your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal is primarily to find out what influences the cost of the stay.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # by convention\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset = pd.read_csv(\"data/lab_3_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things you typically do with a dataset is print out the first few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the columns is equally trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[[\"country\", \"stay_length\", \"age\", \"cost\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get multiple columns at once we need to pass in a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"country\", \"stay_length\", \"age\", \"cost\"]\n",
    "travel_dataset_subset = travel_dataset[columns]\n",
    "travel_dataset_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration: univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue the exploration of our country, destination, stay_length, age and cost variables.\n",
    "\n",
    "1. We will start with a univariate analysis, which means we will explore one (uni) variable (variate) at a time. \n",
    "2. Later on we will move to two (bi) variables (variate) analyses \n",
    "3. We round it up with methods that are able to do multivariate analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that \n",
    "\n",
    "1. **Categorical variables** represent categories or labels (e.g., colors, genders). \n",
    "2. **Numeric variables** represent quantities and can be ordered or measured (e.g., age, height). \n",
    "3. There is a special case called **Ordinal variables**, these are categories where there is a meaningful order (e.g., clothes sizes: small, medium and large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summarizing numeric data\n",
    "\n",
    "üíªüìäüí° TIP: the names of the functions are intuitive. For instance `dataframe[column].min()` gets the minimum of that column. It is equivalent to `select min(column) from dataframe` in SQL. Knowing SQL makes it easy to translate back and forth.\n",
    "\n",
    "üíªüìäüí° TIP: become good friends with the <a href=./Pandas_Cheat_Sheet.pdf>the cheat sheet</a> and the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"cost\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"cost\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"cost\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"cost\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"cost\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### stay length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üíªüìäüí° TIP: there are better ways to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good\n",
    "travel_dataset[[\"age\",\"stay_length\", \"cost\"]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better\n",
    "# Notice how we are passing a list of functions in aggregate\n",
    "travel_dataset[[\"age\",\"stay_length\", \"cost\"]].aggregate([np.mean, np.max, np.median, np.min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best\n",
    "travel_dataset[[\"age\",\"stay_length\", \"cost\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Does anything strike you as odd? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summarizing categorical data\n",
    "\n",
    "üíªüìäüí° TIP: `dataframe[column].value_counts()` is a very powerful method. It is equivalent to `select column, count(column) from dataframe group by column`. If you forget `value_counts()` exists you can get there using your SQL knowledge. `dataframe.groupby(\"column\").count()` also gets you very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration: bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What pairs of variables do you think are interesting to look at?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What methods can you use to do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Carry out these analyses\n",
    "\n",
    "üíªüìäüí° TIP: Things like  `dataframe[[\"column1\", \"column2\"]].groupby(\"column1\").agg([\"min\", \"max\"])` are valid Pandas.\n",
    "\n",
    " In SQL this would be `select column1, min(column2), max(column2) from dataframe group by column1`.\n",
    "\n",
    "üíªüìäüí° TIP: `dataframe[columns].groupby(col1).describe()` is possible\n",
    "\n",
    "üíªüìäüí° TIP: <a href=https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html>Look at</a> `pd.crosstab()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Are there combinations you find suspicious, if so which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì How would you deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Subsetting and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada gets confirmation from her contacts that the data has some issues. The booking system broke down and produced large negative values Additionally, the currency converter for the latest destination broke down.\n",
    "\n",
    "We will help her rectify these mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Removing data: boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally it's a good idea to not alter your original dataset but filter it in a copy. The way Pandas does this is by filtering with a boolean mask. We will demonstrate step by step how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we want gone are the rows where the cost equals `-1000000.00`. We can check for each row if that's the case. \n",
    "\n",
    "Pandas uses a technique called \"broadcasting\" where if you try to do operations between values of different shapes Pandas will try to expand one to make them match.\n",
    "\n",
    "This means you don't need to explicitly turn the value into an array of the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_1.png\" style=\"background-color:white;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_errors = travel_dataset[\"cost\"] != -1000000.00\n",
    "non_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows you to give a boolean array as an index to filter out rows. The rows where the boolean array (also known as a mask) is `True` are kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[non_errors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(travel_dataset) - len(travel_dataset[non_errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned = travel_dataset[non_errors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Make a mask for the people that traveled to Tokyo. Call the variable tokyo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Updating rows the right way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now grab the rows where the destination is Tokyo as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a filtered dataset we can now grab the cost column from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo][\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the rows we can convert the currency by dividing by 158. You will likely attempt to do the following\n",
    "\n",
    "`_dataset_cleaned[tokyo][\"cost\"] /= 158`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo][\"cost\"] /= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the same error as we encountered in the previous session. The way we can get around is is by using `data.loc`.\n",
    "\n",
    "`df.loc` can be quite confusing. It is an object you can slice by using square brackets `[]`. The first element is the **index**. This is typically the column on the far left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.index # Each dataframe has an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokyo.index # Each series has an index too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.loc[tokyo] # Loc filters the dataset where Tokyo is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give columns or a list of columns to `.loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.loc[tokyo, \"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good habit to make a copy before you change your data. If you don't do this and make a mistake you need to rerun your entire script. For a small dataset like this it's not a big problem, but as you scale it can become a bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = _dataset_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_dataset.loc[tokyo, \"cost\"] /= 158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will briefly look at the impact of what we did on our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset[[\"destination\", \"cost\"]].groupby(\"destination\").agg([\"min\", \"max\", \"median\", \"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset[[\"age\", \"cost\", \"stay_length\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset[[\"cost\", \"destination\", \"age\", \"stay_length\"]].groupby(\"destination\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What changed?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì How did the outliers impact our analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### ‚ùì How do interpret the correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "Anscomnbe's quarter: four datasets with an equal correlation.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/1200px-Anscombe%27s_quartet_3.svg.png\" style=\"width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to plotting with Matplotlib, Seaborn and Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have helped Ada so far to gain insights into her data by wrangling it into shape and making tables to summarize data. Now, to further enhance our understanding and visualize the patterns, trends, and potential anomalies, we will be plotting the data. \n",
    "\n",
    "Making data visual simplifies complex datasets and also makes it more intuitive for stakeholders to grasp key takeaways. By transitioning from tabular summaries to graphical plots, we can also communicate more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "\n",
    "<center>\n",
    "<img src=\"https://matplotlib.org/stable/_images/sphx_glr_logos2_003.png\" style=\"background-color:white\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name matplotlib comes from matrix plotting library. It's a descendant from the MATLAB programming language. It's by now an older library (2003) that has some quirks, but it is still important to know the basics of Matplotlib since other Python plotting libraries build on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install\n",
    "# %pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting univariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The table below is a summary of the different types of plots for **numeric data**.\n",
    "\n",
    "| Plot Type          | Description                                           | When to Use                                                      |\n",
    "|--------------------|-------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **Histogram**      | Displays the distribution of a single continuous variable by dividing the data into bins and showing the frequency of observations in each bin. | To visualize the distribution of a variable, especially to identify its central tendency (mean), spread (standard deviation), and skewness (are low or high values more common).  |\n",
    "| **Box Plot (or Whisker Plot)** | Shows the distribution of a variable using quartiles and displays potential outliers. | To get a summary of a variable's distribution in terms of its median, quartiles, and possible outliers. Useful when comparing the distribution across categories. |\n",
    "| **Density Plot (or Kernel Density Plot)** | Provides a smoothed version of a histogram. | To visualize the distribution of a variable in a continuous manner. Particularly useful when comparing the distributions of multiple variables on the same plot. |\n",
    "| **Violin Plot**    | Combines aspects of box plots and density plots.       | To visualize both the distribution and summary statistics of a variable. Especially useful when comparing across different categories. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for plotting is generally `plt.<plotType>(x, y)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(cleaned_dataset[\"cost\"]); # Matplotlib prints things while plotting, the semicolon an suppress it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot provides a comprehensive view of a dataset's distribution, offering more detailed insights than typical tables. The central line within the box represents the median, splitting the data into its lower and upper halves. The box itself is framed by two lines: the lower boundary represents the 25th percentile (or Q1), meaning 25% of the data lies below this value, and the upper boundary denotes the 75th percentile (or Q3), indicating that 75% of the data is below this point.\n",
    "\n",
    "The range between Q3 and Q1 is known as the Interquartile Range (IQR). Beyond the box, the plot extends 'whiskers'. Their \"distance\" is calculated as `1.5 * IQR` both above and below the box, providing a range for typical data points. Any data outside these whiskers can be considered outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What other plots would make sense? Make them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **categorical data**, categories can often serve as a basis for comparison in other plots, like boxplots. This means you can use a single category to differentiate data within such plots. You can also produce the same type of plot multiple times, once for each category, to analyze patterns within individual categories.\n",
    "\n",
    "\n",
    "\n",
    "| Plot Type     | Description                                          | When to Use                                         |\n",
    "|---------------|------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Count Plot**| Represents the frequency or count of each category.  | To see how often each category appears in the data. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
